{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8647d3f4-6e73-4ef2-b00e-37d28b245522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce868c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3930be5-3950-4abf-aed6-18860ff74dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ec46e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_texts_translation=[]\n",
    "target_texts_translation=[]\n",
    "input_characters_translation=set()\n",
    "target_characters_translation=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "827a209f-06f3-4196-b8a4-def5fe6a5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('word.txt','r',encoding='utf-8') as f:\n",
    "    rows=f.read().split('\\n')\n",
    "    count=0\n",
    "for row in rows[:88320]:\n",
    "  \n",
    "    input_text,target_text = row.split('\\t')\n",
    "    \n",
    "    target_text='\\t' + target_text + '\\n'\n",
    "    input_texts_translation.append(input_text.lower())\n",
    "    target_texts_translation.append(target_text.lower())\n",
    "   \n",
    "    input_characters_translation.update(list(input_text.lower()))\n",
    "    target_characters_translation.update(list(target_text.lower()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54301ddf-c452-426d-997f-96590fb732d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88320"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efb76d07-91c5-495d-b7cd-5f581396431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_characters_translation = sorted(list(input_characters_translation))\n",
    "target_characters_translation = sorted(list(target_characters_translation))\n",
    "\n",
    "num_en_chars_translation = len(input_characters_translation)\n",
    "num_dec_chars_translation = len(target_characters_translation)\n",
    "\n",
    "max_input_length_translation = max([len(i) for i in input_texts_translation])\n",
    "max_target_length_translation = max([len(i) for i in target_texts_translation])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1495e48a-06ba-4dff-95d4-ad68dd46825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagofcharacters_translation(input_texts,target_texts):\n",
    "  \n",
    "    en_in_data=[] ; dec_in_data=[] ; dec_tr_data=[]\n",
    "    pad_en=[1]+[0]*(len(input_characters_translation)-1)\n",
    "    pad_dec=[0]*(len(target_characters_translation)) ; pad_dec[2]=1\n",
    "    cv=CountVectorizer(binary=True,tokenizer=lambda txt: txt.split(),stop_words=None,analyzer='char')\n",
    "     \n",
    "    for i,(input_t,target_t) in enumerate(zip(input_texts,target_texts)):     \n",
    "          \n",
    "        cv_inp= cv.fit(input_characters_translation)\n",
    "        en_in_data.append(cv_inp.transform(list(input_t)).toarray().tolist())\n",
    "        cv_tar= cv.fit(target_characters_translation)\t\t\n",
    "        dec_in_data.append(cv_tar.transform(list(target_t)).toarray().tolist())\n",
    "        dec_tr_data.append(cv_tar.transform(list(target_t)[1:]).toarray().tolist())\n",
    "        if len(input_t) < max_input_length_translation:            \n",
    "            for _ in range(max_input_length_translation-len(input_t)):\n",
    "                en_in_data[i].append(pad_en)                \n",
    "        if len(target_t) < max_target_length_translation:\n",
    "              for _ in range(max_target_length_translation-len(target_t)):\n",
    "                dec_in_data[i].append(pad_dec)\n",
    "        if (len(target_t)-1) < max_target_length_translation:\n",
    "              for _ in range(max_target_length_translation-len(target_t)+1):\n",
    "                dec_tr_data[i].append(pad_dec)\n",
    "\n",
    "\n",
    "    en_in_data_translation=np.array(en_in_data,dtype=\"float32\")\n",
    "    dec_in_data_translation=np.array(dec_in_data,dtype=\"float32\")\n",
    "    dec_tr_data_translation=np.array(dec_tr_data,dtype=\"float32\")\n",
    "\n",
    "     \n",
    "    return en_in_data_translation,dec_in_data_translation,dec_tr_data_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ca8d8a9-c8a5-4ec5-8ed2-23827460bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "en_inputs_translation = Input(shape=(None, num_en_chars_translation))\n",
    "\n",
    "\n",
    "encoder_translation = LSTM(256, return_state=True)\n",
    "\n",
    "\n",
    "en_outputs_translation, state_h_translation, state_c_translation = encoder_translation(en_inputs_translation)\n",
    "en_states_translation = [state_h_translation, state_c_translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d9c2789-ed83-46bc-9324-4b6499a0112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dec_inputs_translation = Input(shape=(None, num_dec_chars_translation))\n",
    "\n",
    "\n",
    "dec_lstm_translation = LSTM(256, return_sequences=True, return_state=True)\n",
    "\n",
    "dec_outputs_translation, _, _ = dec_lstm_translation(dec_inputs_translation, initial_state=en_states_translation)\n",
    "\n",
    "dec_dense_translation = Dense(num_dec_chars_translation, activation=\"softmax\")\n",
    "dec_outputs_translation = dec_dense_translation(dec_outputs_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b95461c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_translation = Model([en_inputs_translation, dec_inputs_translation], dec_outputs_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e5a7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'input_characters':input_characters_translation,'input_texts':input_texts_translation[:92],'target_characters':target_characters_translation, 'max_input_length':max_input_length_translation, 'max_target_length':max_target_length_translation, 'num_en_chars':num_en_chars_translation, 'num_dec_chars':num_dec_chars_translation}, open(\"training_data_translation.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24db384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86449f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:551: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "en_in_data_translation,dec_in_data_translation,dec_tr_data_translation = bagofcharacters_translation(input_texts_translation,target_texts_translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "119b1dcd-1d9e-4ed3-ba16-142d23fea55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model_translation.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dc416bf-78c8-4f55-bb5a-f424dc59d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor = \"val_loss\", mode=\"min\" , patience = 5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e3ff844-bf06-445c-ae7d-a9329938f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "552/552 [==============================] - 1144s 2s/step - loss: 0.5110 - accuracy: 0.8678 - val_loss: 0.0951 - val_accuracy: 0.9734\n",
      "Epoch 2/7\n",
      "552/552 [==============================] - 1479s 3s/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0123 - val_accuracy: 0.9946\n",
      "Epoch 3/7\n",
      "552/552 [==============================] - 895s 2s/step - loss: 0.0137 - accuracy: 0.9941 - val_loss: 0.0267 - val_accuracy: 0.9894\n",
      "Epoch 4/7\n",
      "552/552 [==============================] - 997s 2s/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 0.0080 - val_accuracy: 0.9961\n",
      "Epoch 5/7\n",
      "552/552 [==============================] - 957s 2s/step - loss: 0.0086 - accuracy: 0.9956 - val_loss: 0.0072 - val_accuracy: 0.9958\n",
      "Epoch 6/7\n",
      "552/552 [==============================] - 1134s 2s/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 0.0165 - val_accuracy: 0.9940\n",
      "Epoch 7/7\n",
      "552/552 [==============================] - 1355s 2s/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 0.0074 - val_accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_translation\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_translation\\assets\n"
     ]
    }
   ],
   "source": [
    "model_translation.fit(\n",
    "    [en_in_data_translation, dec_in_data_translation],\n",
    "    dec_tr_data_translation,\n",
    "    batch_size=128,\n",
    "    epochs=7,\n",
    "    validation_split=0.2,\n",
    "    \n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_translation.save(\"model_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a03dfd2-38cb-499b-b17d-48129a7162f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datafile_translation = pickle.load(open(\"training_data_translation.pkl\",\"rb\"))\n",
    "input_characters_translation = datafile_translation['input_characters']\n",
    "target_characters_translation = datafile_translation['target_characters']\n",
    "max_input_length_translation = datafile_translation['max_input_length']\n",
    "max_target_length_translation = datafile_translation['max_target_length']\n",
    "num_en_chars_translation = datafile_translation['num_en_chars']\n",
    "num_dec_chars_translation = datafile_translation['num_dec_chars']\n",
    "input_texts_translation=datafile_translation['input_texts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16c23475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " 'ं',\n",
       " 'आ',\n",
       " 'उ',\n",
       " 'क',\n",
       " 'ख',\n",
       " 'ग',\n",
       " 'घ',\n",
       " 'च',\n",
       " 'ज',\n",
       " 'झ',\n",
       " 'ट',\n",
       " 'ड',\n",
       " 'ण',\n",
       " 'त',\n",
       " 'द',\n",
       " 'न',\n",
       " 'प',\n",
       " 'फ',\n",
       " 'ब',\n",
       " 'भ',\n",
       " 'म',\n",
       " 'य',\n",
       " 'र',\n",
       " 'ल',\n",
       " 'ळ',\n",
       " 'व',\n",
       " 'श',\n",
       " 'स',\n",
       " 'ह',\n",
       " 'ा',\n",
       " 'ि',\n",
       " 'ी',\n",
       " 'ु',\n",
       " 'ू',\n",
       " 'े',\n",
       " 'ो',\n",
       " '्']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab46fff-fda4-4f3d-a4a5-d5b3b72c7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_translation = models.load_model(\"model_translation\")\n",
    "\n",
    "enc_outputs_translation, state_h_enc_translation, state_c_enc_translation = model_translation.layers[2].output \n",
    "\n",
    "\n",
    "en_model_translation = Model(model_translation.input[0], [state_h_enc_translation, state_c_enc_translation])\n",
    "\n",
    "dec_state_input_h_translation = Input(shape=(256,))\n",
    "dec_state_input_c_translation = Input(shape=(256,))\n",
    "dec_states_inputs_translation = [dec_state_input_h_translation, dec_state_input_c_translation]\n",
    "\n",
    "\n",
    "dec_outputs_translation, state_h_dec_translation, state_c_dec_translation = dec_lstm_translation(\n",
    "    model_translation.input[1], initial_state=dec_states_inputs_translation\n",
    ")\n",
    "\n",
    "dec_states_translation = [state_h_dec_translation, state_c_dec_translation]\n",
    "dec_dense_translation = model_translation.layers[4]\n",
    "dec_outputs_translation = dec_dense_translation(dec_outputs_translation)\n",
    "\n",
    "\n",
    "dec_model_translation = Model(\n",
    "    [model_translation.input[1]] + dec_states_inputs_translation, [dec_outputs_translation] + dec_states_translation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ef5e979-b62d-42e7-86e8-45a798aaddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_translation(input_seq):\n",
    "    \n",
    "    reverse_target_char_index = dict(enumerate(target_characters_translation))\n",
    "    \n",
    "    states_value = en_model_translation.predict(input_seq)\n",
    "    cv=CountVectorizer(binary=True,tokenizer=lambda txt: txt.split(),stop_words=None,analyzer='char')\n",
    " \n",
    "    co=cv.fit(target_characters_translation) \n",
    "    target_seq=np.array([co.transform(list(\"\\t\")).toarray().tolist()],dtype=\"float32\")\n",
    "\n",
    "   \n",
    "    stop_condition = False\n",
    "   \n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_chars, h, c = dec_model_translation.predict([target_seq] + states_value)\n",
    "\n",
    "        \n",
    "        char_index = np.argmax(output_chars[0, -1, :])\n",
    "        text_char = reverse_target_char_index[char_index]\n",
    "        decoded_sentence += text_char\n",
    "        \n",
    "      \n",
    "        if text_char == \"\\n\" or len(decoded_sentence) > max_target_length_translation:\n",
    "            stop_condition = True\n",
    "   \n",
    "        target_seq = np.zeros((1, 1, num_dec_chars_translation))\n",
    "        target_seq[0, 0, char_index] = 1.0\n",
    "        states_value = [h, c]\n",
    "   \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f61c231-26ae-4cfb-93d2-33a794894cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def bagofcharacter_translation(input_t):\n",
    "        cv=CountVectorizer(binary=True,tokenizer=lambda txt:\n",
    "        txt.split(),stop_words=None,analyzer='char') \n",
    "        en_in_data=[] ; pad_en=[1]+[0]*(len(input_characters_translation)-1)\n",
    "    \n",
    "        cv_inp= cv.fit(input_characters_translation)\n",
    "        en_in_data.append(cv_inp.transform(list(input_t)).toarray().tolist())\n",
    "    \n",
    "        if len(input_t)< max_input_length_translation:\n",
    "          for _ in range(max_input_length_translation-len(input_t)):\n",
    "            en_in_data[0].append(pad_en)\n",
    "    \n",
    "        return np.array(en_in_data,dtype=\"float32\")\n",
    "    \n",
    "\n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1be32dbb-9db1-43ca-9f8d-9a8cccc48d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in input_texts_translation[:92]:\n",
    "    output_texts=[]\n",
    "    print(\"input : \"+ x)\n",
    "    #x=  input( 'Enter eng sentence : ' ) \n",
    "    input_text = x.split(' ') \n",
    "    output_texts=\"\"  \n",
    "    en_in_data = bagofcharacter_translation( x.lower()+\".\")    \n",
    "    x=decode_sequence_translation(en_in_data)\n",
    "    output_texts+=\" \"+ x         \n",
    "    print(\"output : \"+output_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0241392-7888-4204-9a17-8528ca8e623a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bb25a-cbec-48af-ab38-084929548bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84da431-fdb4-41d8-81dd-252101e65698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef5794-9cee-47c3-a2e3-56e7b8c77353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc6714-22ab-4418-bd58-c5ec04a80730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
